{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "#import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder():\n",
    "    img_size = 224\n",
    "    images = []\n",
    "    image_paths = 'E:/Drowsiness/Data_CNN/train/alert/'\n",
    "    for filename in os.listdir(image_paths):\n",
    "        img = cv2.imread(os.path.join(image_paths,filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            images.append([np.array(img),[1,0]])\n",
    "    \n",
    "    image_paths = 'E:/Drowsiness/Data_CNN/train/drowsy/'\n",
    "    for filename in os.listdir(image_paths):\n",
    "        img = cv2.imread(os.path.join(image_paths,filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            images.append([np.array(img),[0,1]])\n",
    "    shuffle(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder_test():\n",
    "    img_size = 224\n",
    "    images = []\n",
    "    image_paths = 'E:/Drowsiness/Data_CNN/test/alert/'\n",
    "    for filename in os.listdir(image_paths):\n",
    "        img = cv2.imread(os.path.join(image_paths,filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            images.append([np.array(img),[1,0]])\n",
    "    \n",
    "    image_paths = 'E:/Drowsiness/Data_CNN/test/drowsy/'\n",
    "    for filename in os.listdir(image_paths):\n",
    "        img = cv2.imread(os.path.join(image_paths,filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            images.append([np.array(img),[0,1]])\n",
    "    shuffle(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_images_from_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4851, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([i[0] for i in train]).reshape(-1,224,224,3)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([i[1] for i in train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=30,width_shift_range=0.2)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                                               input_shape=(224,224,3),\n",
    "                                               weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 111, 111, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 111, 111, 32) 96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 111, 111, 32) 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 109, 109, 32) 9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 109, 109, 32) 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 109, 109, 32) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 109, 109, 64) 18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 109, 109, 64) 192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 109, 109, 64) 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 54, 54, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 54, 54, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 54, 54, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 52, 52, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 52, 52, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 52, 52, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 25, 25, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 25, 25, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 25, 25, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 25, 25, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 25, 25, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 25, 25, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 25, 25, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 25, 25, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 25, 25, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 25, 25, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 25, 25, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 25, 25, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 25, 25, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 25, 25, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 25, 25, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 25, 25, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 25, 25, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 25, 25, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 25, 25, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 25, 25, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 25, 25, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 25, 25, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 25, 25, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 25, 25, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 25, 25, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 25, 25, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 25, 25, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 25, 25, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 25, 25, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 25, 25, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 25, 25, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 25, 25, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 25, 25, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 25, 25, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 25, 25, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 25, 25, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 25, 25, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 25, 25, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 25, 25, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 25, 25, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 25, 25, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 25, 25, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 25, 25, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 25, 25, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 25, 25, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 25, 25, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 25, 25, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 25, 25, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 25, 25, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 25, 25, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 25, 25, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 25, 25, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 25, 25, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 25, 25, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 25, 25, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 25, 25, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 12, 12, 96)   82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 12, 12, 384)  1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 12, 12, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 12, 12, 384)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 12, 12, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 12, 12, 128)  384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 12, 12, 128)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 12, 12, 128)  114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 12, 12, 128)  114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 12, 12, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 12, 12, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 12, 12, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 12, 12, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 12, 12, 128)  114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 12, 12, 128)  114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 12, 12, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 12, 12, 128)  384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 12, 12, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 12, 12, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 12, 12, 192)  172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 12, 12, 192)  172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 12, 12, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 12, 12, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 12, 12, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 12, 12, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 12, 12, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 12, 12, 192)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 12, 12, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 12, 12, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 12, 12, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 12, 12, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 12, 12, 160)  179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 12, 12, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 12, 12, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 12, 12, 160)  179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 12, 12, 160)  480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 12, 12, 160)  480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 12, 12, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 12, 12, 160)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 12, 12, 160)  179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 12, 12, 160)  179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 12, 12, 160)  480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 12, 12, 160)  480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 12, 12, 160)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 12, 12, 160)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 12, 12, 192)  215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 12, 12, 192)  215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 12, 12, 192)  576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 12, 12, 192)  576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 12, 12, 192)  576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 12, 12, 192)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 12, 12, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 12, 12, 192)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 12, 12, 160)  480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 12, 12, 160)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 12, 12, 160)  179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 12, 12, 160)  480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 12, 12, 160)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 12, 12, 160)  179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 12, 12, 160)  480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 12, 12, 160)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 12, 12, 160)  179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 12, 12, 160)  179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 12, 12, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 12, 12, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 12, 12, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 12, 12, 192)  215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 12, 12, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 12, 12, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 12, 12, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 12, 12, 192)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 12, 12, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 12, 12, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 12, 12, 192)  576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 12, 12, 192)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 12, 12, 192)  258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 12, 12, 192)  576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 12, 12, 192)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 12, 12, 192)  258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 12, 12, 192)  576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 12, 12, 192)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 12, 12, 192)  258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 12, 12, 192)  258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 12, 12, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 12, 12, 192)  576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 12, 12, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 12, 192)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 12, 12, 192)  258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 12, 12, 192)  258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 12, 12, 192)  576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 12, 12, 192)  576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 12, 12, 192)  576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 12, 12, 192)  576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 12, 12, 192)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 12, 12, 192)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 12, 12, 192)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 12, 12, 192)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 12, 12, 192)  576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 12, 12, 192)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 12, 12, 192)  258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 12, 12, 192)  576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 12, 12, 192)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 12, 12, 192)  258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 12, 12, 192)  576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 12, 12, 192)  576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 12, 12, 192)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 12, 12, 192)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 5, 5, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 5, 5, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 5, 5, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 5, 5, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 5, 5, 320)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 5, 5, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 5, 5, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 5, 5, 448)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 5, 5, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 5, 5, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 5, 5, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 5, 5, 384)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 5, 5, 384)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 5, 5, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 5, 5, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 5, 5, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 5, 5, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 5, 5, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 5, 5, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 5, 5, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 5, 5, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 5, 5, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 5, 5, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 5, 5, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 5, 5, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 5, 5, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 5, 5, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 5, 5, 320)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 5, 5, 192)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 5, 5, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 5, 5, 448)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 5, 5, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 5, 5, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 5, 5, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 5, 5, 384)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 5, 5, 384)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 5, 5, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 5, 5, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 5, 5, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 5, 5, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 5, 5, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 5, 5, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 5, 5, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 5, 5, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 5, 5, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 5, 5, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 5, 5, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 5, 5, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 5, 5, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 5, 5, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 5, 5, 320)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5, 5, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 5, 5, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "averge_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "prediction_layer = tf.keras.layers.Dense(units=2,activation = 'softmax')(averge_pooling_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs=base_model.input,outputs = prediction_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 111, 111, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 111, 111, 32) 96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 111, 111, 32) 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 109, 109, 32) 9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 109, 109, 32) 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 109, 109, 32) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 109, 109, 64) 18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 109, 109, 64) 192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 109, 109, 64) 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 54, 54, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 54, 54, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 54, 54, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 52, 52, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 52, 52, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 52, 52, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 25, 25, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 25, 25, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 25, 25, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 25, 25, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 25, 25, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 25, 25, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 25, 25, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 25, 25, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 25, 25, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 25, 25, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 25, 25, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 25, 25, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 25, 25, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 25, 25, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 25, 25, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 25, 25, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 25, 25, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 25, 25, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 25, 25, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 25, 25, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 25, 25, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 25, 25, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 25, 25, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 25, 25, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 25, 25, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 25, 25, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 25, 25, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 25, 25, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 25, 25, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 25, 25, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 25, 25, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 25, 25, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 25, 25, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 25, 25, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 25, 25, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 25, 25, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 25, 25, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 25, 25, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 25, 25, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 25, 25, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 25, 25, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 25, 25, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 25, 25, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 25, 25, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 25, 25, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 25, 25, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 25, 25, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 25, 25, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 25, 25, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 25, 25, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 25, 25, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 25, 25, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 25, 25, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 25, 25, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 25, 25, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 25, 25, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 12, 12, 96)   82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 12, 12, 384)  1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 12, 12, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 12, 12, 384)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 12, 12, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 12, 12, 128)  384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 12, 12, 128)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 12, 12, 128)  114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 12, 12, 128)  114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 12, 12, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 12, 12, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 12, 12, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 12, 12, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 12, 12, 128)  114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 12, 12, 128)  114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 12, 12, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 12, 12, 128)  384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 12, 12, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 12, 12, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 12, 12, 192)  172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 12, 12, 192)  172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 12, 12, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 12, 12, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 12, 12, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 12, 12, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 12, 12, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 12, 12, 192)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 12, 12, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 12, 12, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 12, 12, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 12, 12, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 12, 12, 160)  179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 12, 12, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 12, 12, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 12, 12, 160)  179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 12, 12, 160)  480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 12, 12, 160)  480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 12, 12, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 12, 12, 160)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 12, 12, 160)  179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 12, 12, 160)  179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 12, 12, 160)  480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 12, 12, 160)  480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 12, 12, 160)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 12, 12, 160)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 12, 12, 192)  215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 12, 12, 192)  215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 12, 12, 192)  576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 12, 12, 192)  576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 12, 12, 192)  576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 12, 12, 192)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 12, 12, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 12, 12, 192)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 12, 12, 160)  480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 12, 12, 160)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 12, 12, 160)  179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 12, 12, 160)  480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 12, 12, 160)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 12, 12, 160)  179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 12, 12, 160)  480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 12, 12, 160)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 12, 12, 160)  179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 12, 12, 160)  179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 12, 12, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 12, 12, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 12, 12, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 12, 12, 192)  215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 12, 12, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 12, 12, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 12, 12, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 12, 12, 192)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 12, 12, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 12, 12, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 12, 12, 192)  576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 12, 12, 192)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 12, 12, 192)  258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 12, 12, 192)  576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 12, 12, 192)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 12, 12, 192)  258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 12, 12, 192)  576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 12, 12, 192)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 12, 12, 192)  258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 12, 12, 192)  258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 12, 12, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 12, 12, 192)  576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 12, 12, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 12, 192)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 12, 12, 192)  258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 12, 12, 192)  258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 12, 12, 192)  576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 12, 12, 192)  576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 12, 12, 192)  576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 12, 12, 192)  576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 12, 12, 192)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 12, 12, 192)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 12, 12, 192)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 12, 12, 192)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 12, 12, 192)  576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 12, 12, 192)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 12, 12, 192)  258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 12, 12, 192)  576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 12, 12, 192)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 12, 12, 192)  258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 12, 12, 192)  576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 12, 12, 192)  576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 12, 12, 192)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 12, 12, 192)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 5, 5, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 5, 5, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 5, 5, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 5, 5, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 5, 5, 320)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 5, 5, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 5, 5, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 5, 5, 448)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 5, 5, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 5, 5, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 5, 5, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 5, 5, 384)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 5, 5, 384)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 5, 5, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 5, 5, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 5, 5, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 5, 5, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 5, 5, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 5, 5, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 5, 5, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 5, 5, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 5, 5, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 5, 5, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 5, 5, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 5, 5, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 5, 5, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 5, 5, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 5, 5, 320)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 5, 5, 192)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 5, 5, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 5, 5, 448)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 5, 5, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 5, 5, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 5, 5, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 5, 5, 384)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 5, 5, 384)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 5, 5, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 5, 5, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 5, 5, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 5, 5, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 5, 5, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 5, 5, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 5, 5, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 5, 5, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 5, 5, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 5, 5, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 5, 5, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 5, 5, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 5, 5, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 5, 5, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 5, 5, 320)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5, 5, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 5, 5, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            4098        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 21,806,882\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3880 samples, validate on 971 samples\n",
      "Epoch 1/25\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.6627 - acc: 0.6101 - val_loss: 0.7018 - val_acc: 0.5870\n",
      "Epoch 2/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.6244 - acc: 0.6485 - val_loss: 0.7054 - val_acc: 0.6117\n",
      "Epoch 3/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.5944 - acc: 0.6786 - val_loss: 0.6826 - val_acc: 0.6169\n",
      "Epoch 4/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.5681 - acc: 0.7028 - val_loss: 0.6732 - val_acc: 0.6354\n",
      "Epoch 5/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.5541 - acc: 0.7227 - val_loss: 0.6787 - val_acc: 0.6509\n",
      "Epoch 6/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.5417 - acc: 0.7284 - val_loss: 0.6756 - val_acc: 0.6622\n",
      "Epoch 7/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.5276 - acc: 0.7438 - val_loss: 0.6649 - val_acc: 0.6622\n",
      "Epoch 8/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.5049 - acc: 0.7575 - val_loss: 0.6788 - val_acc: 0.6643\n",
      "Epoch 9/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.5031 - acc: 0.7567 - val_loss: 0.7437 - val_acc: 0.6488\n",
      "Epoch 10/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4946 - acc: 0.7662 - val_loss: 0.6945 - val_acc: 0.6684\n",
      "Epoch 11/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4861 - acc: 0.7758 - val_loss: 0.7507 - val_acc: 0.6560\n",
      "Epoch 12/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4843 - acc: 0.7675 - val_loss: 0.6896 - val_acc: 0.6725\n",
      "Epoch 13/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4758 - acc: 0.7796 - val_loss: 0.6858 - val_acc: 0.6746\n",
      "Epoch 14/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4746 - acc: 0.7848 - val_loss: 0.7509 - val_acc: 0.6612\n",
      "Epoch 15/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4640 - acc: 0.7892 - val_loss: 0.7183 - val_acc: 0.6715\n",
      "Epoch 16/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4581 - acc: 0.7918 - val_loss: 0.7538 - val_acc: 0.6643\n",
      "Epoch 17/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4635 - acc: 0.7851 - val_loss: 0.7531 - val_acc: 0.6684\n",
      "Epoch 18/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4482 - acc: 0.7941 - val_loss: 0.7793 - val_acc: 0.6674\n",
      "Epoch 19/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4459 - acc: 0.7943 - val_loss: 0.7424 - val_acc: 0.6704\n",
      "Epoch 20/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4434 - acc: 0.8036 - val_loss: 0.7639 - val_acc: 0.6704\n",
      "Epoch 21/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4401 - acc: 0.8023 - val_loss: 0.7667 - val_acc: 0.6735\n",
      "Epoch 22/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4390 - acc: 0.8041 - val_loss: 0.7534 - val_acc: 0.6704\n",
      "Epoch 23/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4371 - acc: 0.8028 - val_loss: 0.8468 - val_acc: 0.6653\n",
      "Epoch 24/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4238 - acc: 0.8157 - val_loss: 0.7177 - val_acc: 0.6766\n",
      "Epoch 25/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4395 - acc: 0.7915 - val_loss: 0.8175 - val_acc: 0.6777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x263eac4e4c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GoogLeNet_25.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 25 <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = load_model('GoogLeNet_25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 111, 111, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 111, 111, 32) 96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 111, 111, 32) 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 109, 109, 32) 9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 109, 109, 32) 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 109, 109, 32) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 109, 109, 64) 18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 109, 109, 64) 192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 109, 109, 64) 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 54, 54, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 54, 54, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 54, 54, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 52, 52, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 52, 52, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 52, 52, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 25, 25, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 25, 25, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 25, 25, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 25, 25, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 25, 25, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 25, 25, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 25, 25, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 25, 25, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 25, 25, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 25, 25, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 25, 25, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 25, 25, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 25, 25, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 25, 25, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 25, 25, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 25, 25, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 25, 25, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 25, 25, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 25, 25, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 25, 25, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 25, 25, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 25, 25, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 25, 25, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 25, 25, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 25, 25, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 25, 25, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 25, 25, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 25, 25, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 25, 25, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 25, 25, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 25, 25, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 25, 25, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 25, 25, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 25, 25, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 25, 25, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 25, 25, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 25, 25, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 25, 25, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 25, 25, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 25, 25, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 25, 25, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 25, 25, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 25, 25, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 25, 25, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 25, 25, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 25, 25, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 25, 25, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 25, 25, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 25, 25, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 25, 25, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 25, 25, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 25, 25, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 25, 25, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 25, 25, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 25, 25, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 25, 25, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 12, 12, 96)   82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 12, 12, 384)  1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 12, 12, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 12, 12, 384)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 12, 12, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 12, 12, 128)  384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 12, 12, 128)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 12, 12, 128)  114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 12, 12, 128)  114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 12, 12, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 12, 12, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 12, 12, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 12, 12, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 12, 12, 128)  114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 12, 12, 128)  114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 12, 12, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 12, 12, 128)  384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 12, 12, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 12, 12, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 12, 12, 192)  172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 12, 12, 192)  172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 12, 12, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 12, 12, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 12, 12, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 12, 12, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 12, 12, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 12, 12, 192)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 12, 12, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 12, 12, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 12, 12, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 12, 12, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 12, 12, 160)  179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 12, 12, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 12, 12, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 12, 12, 160)  179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 12, 12, 160)  480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 12, 12, 160)  480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 12, 12, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 12, 12, 160)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 12, 12, 160)  179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 12, 12, 160)  179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 12, 12, 160)  480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 12, 12, 160)  480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 12, 12, 160)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 12, 12, 160)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 12, 12, 192)  215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 12, 12, 192)  215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 12, 12, 192)  576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 12, 12, 192)  576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 12, 12, 192)  576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 12, 12, 192)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 12, 12, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 12, 12, 192)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 12, 12, 160)  480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 12, 12, 160)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 12, 12, 160)  179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 12, 12, 160)  480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 12, 12, 160)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 12, 12, 160)  179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 12, 12, 160)  480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 12, 12, 160)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 12, 12, 160)  179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 12, 12, 160)  179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 12, 12, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 12, 12, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 12, 12, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 12, 12, 192)  215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 12, 12, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 12, 12, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 12, 12, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 12, 12, 192)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 12, 12, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 12, 12, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 12, 12, 192)  576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 12, 12, 192)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 12, 12, 192)  258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 12, 12, 192)  576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 12, 12, 192)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 12, 12, 192)  258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 12, 12, 192)  576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 12, 12, 192)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 12, 12, 192)  258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 12, 12, 192)  258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 12, 12, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 12, 12, 192)  576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 12, 12, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 12, 192)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 12, 12, 192)  258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 12, 12, 192)  258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 12, 12, 192)  576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 12, 12, 192)  576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 12, 12, 192)  576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 12, 12, 192)  576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 12, 12, 192)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 12, 12, 192)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 12, 12, 192)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 12, 12, 192)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 12, 12, 192)  576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 12, 12, 192)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 12, 12, 192)  258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 12, 12, 192)  576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 12, 12, 192)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 12, 12, 192)  258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 12, 12, 192)  576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 12, 12, 192)  576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 12, 12, 192)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 12, 12, 192)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 5, 5, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 5, 5, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 5, 5, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 5, 5, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 5, 5, 320)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 5, 5, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 5, 5, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 5, 5, 448)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 5, 5, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 5, 5, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 5, 5, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 5, 5, 384)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 5, 5, 384)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 5, 5, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 5, 5, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 5, 5, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 5, 5, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 5, 5, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 5, 5, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 5, 5, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 5, 5, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 5, 5, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 5, 5, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 5, 5, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 5, 5, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 5, 5, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 5, 5, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 5, 5, 320)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 5, 5, 192)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 5, 5, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 5, 5, 448)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 5, 5, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 5, 5, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 5, 5, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 5, 5, 384)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 5, 5, 384)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 5, 5, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 5, 5, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 5, 5, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 5, 5, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 5, 5, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 5, 5, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 5, 5, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 5, 5, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 5, 5, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 5, 5, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 5, 5, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 5, 5, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 5, 5, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 5, 5, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 5, 5, 320)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5, 5, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 5, 5, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            4098        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 21,806,882\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3880 samples, validate on 971 samples\n",
      "Epoch 1/25\n",
      "3880/3880 [==============================] - 41s 11ms/sample - loss: 0.4218 - acc: 0.8116 - val_loss: 0.8937 - val_acc: 0.6488\n",
      "Epoch 2/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4260 - acc: 0.8054 - val_loss: 0.8855 - val_acc: 0.6478\n",
      "Epoch 3/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4191 - acc: 0.8186 - val_loss: 0.8920 - val_acc: 0.6488\n",
      "Epoch 4/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4219 - acc: 0.8085 - val_loss: 0.8497 - val_acc: 0.6519\n",
      "Epoch 5/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4173 - acc: 0.8162 - val_loss: 0.8884 - val_acc: 0.6447\n",
      "Epoch 6/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4119 - acc: 0.8137 - val_loss: 0.8047 - val_acc: 0.6694\n",
      "Epoch 7/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4136 - acc: 0.8232 - val_loss: 0.9403 - val_acc: 0.6447\n",
      "Epoch 8/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4105 - acc: 0.8152 - val_loss: 0.8492 - val_acc: 0.6622\n",
      "Epoch 9/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4136 - acc: 0.8142 - val_loss: 0.9034 - val_acc: 0.6437\n",
      "Epoch 10/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4122 - acc: 0.8204 - val_loss: 0.8708 - val_acc: 0.6529\n",
      "Epoch 11/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.4052 - acc: 0.8206 - val_loss: 0.9403 - val_acc: 0.6457\n",
      "Epoch 12/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4078 - acc: 0.8183 - val_loss: 0.9219 - val_acc: 0.6478\n",
      "Epoch 13/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4050 - acc: 0.8175 - val_loss: 0.9115 - val_acc: 0.6498\n",
      "Epoch 14/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.4044 - acc: 0.8204 - val_loss: 0.9886 - val_acc: 0.6395\n",
      "Epoch 15/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3941 - acc: 0.8276 - val_loss: 0.8451 - val_acc: 0.6612\n",
      "Epoch 16/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3910 - acc: 0.8276 - val_loss: 0.9540 - val_acc: 0.6478\n",
      "Epoch 17/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3944 - acc: 0.8247 - val_loss: 0.9404 - val_acc: 0.6468\n",
      "Epoch 18/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3905 - acc: 0.8307 - val_loss: 1.0102 - val_acc: 0.6375\n",
      "Epoch 19/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3930 - acc: 0.8263 - val_loss: 0.9618 - val_acc: 0.6416\n",
      "Epoch 20/25\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3882 - acc: 0.8353 - val_loss: 0.9188 - val_acc: 0.6509\n",
      "Epoch 21/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3884 - acc: 0.8322 - val_loss: 0.9012 - val_acc: 0.6540\n",
      "Epoch 22/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3855 - acc: 0.8345 - val_loss: 1.0362 - val_acc: 0.6365\n",
      "Epoch 23/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3865 - acc: 0.8265 - val_loss: 0.9726 - val_acc: 0.6447\n",
      "Epoch 24/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3841 - acc: 0.8322 - val_loss: 1.1771 - val_acc: 0.6292\n",
      "Epoch 25/25\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3811 - acc: 0.8312 - val_loss: 1.0818 - val_acc: 0.6344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22dba3d0c08>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3880 samples, validate on 971 samples\n",
      "Epoch 1/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3791 - acc: 0.8351 - val_loss: 1.0110 - val_acc: 0.6447\n",
      "Epoch 2/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3798 - acc: 0.8335 - val_loss: 1.0445 - val_acc: 0.6365\n",
      "Epoch 3/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3779 - acc: 0.8394 - val_loss: 1.0042 - val_acc: 0.6437\n",
      "Epoch 4/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3811 - acc: 0.8348 - val_loss: 0.9138 - val_acc: 0.6540\n",
      "Epoch 5/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3830 - acc: 0.8312 - val_loss: 1.0945 - val_acc: 0.6344\n",
      "Epoch 6/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3678 - acc: 0.8410 - val_loss: 1.1622 - val_acc: 0.6303\n",
      "Epoch 7/50\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3796 - acc: 0.8348 - val_loss: 1.0182 - val_acc: 0.6416\n",
      "Epoch 8/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3713 - acc: 0.8356 - val_loss: 1.0345 - val_acc: 0.6416\n",
      "Epoch 9/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3793 - acc: 0.8369 - val_loss: 0.9772 - val_acc: 0.6478\n",
      "Epoch 10/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3669 - acc: 0.8420 - val_loss: 1.0240 - val_acc: 0.6437\n",
      "Epoch 11/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3690 - acc: 0.8425 - val_loss: 1.0878 - val_acc: 0.6375\n",
      "Epoch 12/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3734 - acc: 0.8371 - val_loss: 0.9546 - val_acc: 0.6540\n",
      "Epoch 13/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3727 - acc: 0.8348 - val_loss: 1.1539 - val_acc: 0.6303\n",
      "Epoch 14/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3698 - acc: 0.8361 - val_loss: 0.9937 - val_acc: 0.6478\n",
      "Epoch 15/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3672 - acc: 0.8402 - val_loss: 1.0550 - val_acc: 0.6416\n",
      "Epoch 16/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3699 - acc: 0.8405 - val_loss: 1.1268 - val_acc: 0.6334\n",
      "Epoch 17/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3709 - acc: 0.8397 - val_loss: 1.1246 - val_acc: 0.6344\n",
      "Epoch 18/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3666 - acc: 0.8387 - val_loss: 1.1343 - val_acc: 0.6323\n",
      "Epoch 19/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3779 - acc: 0.8366 - val_loss: 1.0506 - val_acc: 0.6406\n",
      "Epoch 20/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3662 - acc: 0.8487 - val_loss: 1.0033 - val_acc: 0.6478\n",
      "Epoch 21/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3636 - acc: 0.8472 - val_loss: 1.1089 - val_acc: 0.6365\n",
      "Epoch 22/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3646 - acc: 0.8461 - val_loss: 1.1617 - val_acc: 0.6334\n",
      "Epoch 23/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3628 - acc: 0.8492 - val_loss: 1.2014 - val_acc: 0.6323\n",
      "Epoch 24/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3645 - acc: 0.8412 - val_loss: 1.1434 - val_acc: 0.6334\n",
      "Epoch 25/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3624 - acc: 0.8405 - val_loss: 1.1597 - val_acc: 0.6354\n",
      "Epoch 26/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3550 - acc: 0.8492 - val_loss: 1.1514 - val_acc: 0.6344\n",
      "Epoch 27/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3502 - acc: 0.8562 - val_loss: 1.1558 - val_acc: 0.6334\n",
      "Epoch 28/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3624 - acc: 0.8415 - val_loss: 1.0772 - val_acc: 0.6416\n",
      "Epoch 29/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3613 - acc: 0.8394 - val_loss: 1.2208 - val_acc: 0.6303\n",
      "Epoch 30/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3612 - acc: 0.8420 - val_loss: 1.1321 - val_acc: 0.6344\n",
      "Epoch 31/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3497 - acc: 0.8518 - val_loss: 1.1571 - val_acc: 0.6344\n",
      "Epoch 32/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3564 - acc: 0.8448 - val_loss: 1.1788 - val_acc: 0.6344\n",
      "Epoch 33/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3561 - acc: 0.8443 - val_loss: 1.1398 - val_acc: 0.6354\n",
      "Epoch 34/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3552 - acc: 0.8523 - val_loss: 1.2891 - val_acc: 0.6313\n",
      "Epoch 35/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3523 - acc: 0.8479 - val_loss: 1.0453 - val_acc: 0.6457\n",
      "Epoch 36/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3589 - acc: 0.8430 - val_loss: 1.2302 - val_acc: 0.6323\n",
      "Epoch 37/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3563 - acc: 0.8487 - val_loss: 1.1443 - val_acc: 0.6354\n",
      "Epoch 38/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3461 - acc: 0.8546 - val_loss: 1.2049 - val_acc: 0.6334\n",
      "Epoch 39/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3493 - acc: 0.8479 - val_loss: 1.3736 - val_acc: 0.6292\n",
      "Epoch 40/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3525 - acc: 0.8469 - val_loss: 1.1931 - val_acc: 0.6344\n",
      "Epoch 41/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3550 - acc: 0.8466 - val_loss: 1.3201 - val_acc: 0.6303\n",
      "Epoch 42/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3476 - acc: 0.8472 - val_loss: 1.3492 - val_acc: 0.6292\n",
      "Epoch 43/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3439 - acc: 0.8552 - val_loss: 1.2825 - val_acc: 0.6334\n",
      "Epoch 44/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3411 - acc: 0.8531 - val_loss: 1.2118 - val_acc: 0.6323\n",
      "Epoch 45/50\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3492 - acc: 0.8505 - val_loss: 1.2619 - val_acc: 0.6344\n",
      "Epoch 46/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3444 - acc: 0.8585 - val_loss: 1.2988 - val_acc: 0.6344\n",
      "Epoch 47/50\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3455 - acc: 0.8585 - val_loss: 1.1843 - val_acc: 0.6354\n",
      "Epoch 48/50\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3511 - acc: 0.8526 - val_loss: 1.4466 - val_acc: 0.6251\n",
      "Epoch 49/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3469 - acc: 0.8490 - val_loss: 1.1470 - val_acc: 0.6365\n",
      "Epoch 50/50\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3408 - acc: 0.8541 - val_loss: 1.1828 - val_acc: 0.6365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22de053f6c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GoogLeNet_100.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 100 <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('GoogLeNet_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3880 samples, validate on 971 samples\n",
      "Epoch 1/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3500 - acc: 0.8490 - val_loss: 1.3564 - val_acc: 0.6292\n",
      "Epoch 2/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3502 - acc: 0.8500 - val_loss: 1.2813 - val_acc: 0.6344\n",
      "Epoch 3/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3498 - acc: 0.8497 - val_loss: 1.1264 - val_acc: 0.6375\n",
      "Epoch 4/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3408 - acc: 0.8544 - val_loss: 1.3103 - val_acc: 0.6323\n",
      "Epoch 5/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3435 - acc: 0.8423 - val_loss: 1.4214 - val_acc: 0.6282\n",
      "Epoch 6/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3443 - acc: 0.8562 - val_loss: 1.1144 - val_acc: 0.6375\n",
      "Epoch 7/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3501 - acc: 0.8407 - val_loss: 1.2812 - val_acc: 0.6344\n",
      "Epoch 8/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3426 - acc: 0.8575 - val_loss: 1.2305 - val_acc: 0.6375\n",
      "Epoch 9/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3348 - acc: 0.8590 - val_loss: 1.0582 - val_acc: 0.6447\n",
      "Epoch 10/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3375 - acc: 0.8626 - val_loss: 1.4016 - val_acc: 0.6313\n",
      "Epoch 11/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3506 - acc: 0.8436 - val_loss: 1.4131 - val_acc: 0.6292\n",
      "Epoch 12/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3413 - acc: 0.8541 - val_loss: 1.3384 - val_acc: 0.6334\n",
      "Epoch 13/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3295 - acc: 0.8642 - val_loss: 1.1380 - val_acc: 0.6375\n",
      "Epoch 14/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3357 - acc: 0.8575 - val_loss: 1.1921 - val_acc: 0.6365\n",
      "Epoch 15/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3431 - acc: 0.8546 - val_loss: 1.2487 - val_acc: 0.6365\n",
      "Epoch 16/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3407 - acc: 0.8564 - val_loss: 1.3746 - val_acc: 0.6313\n",
      "Epoch 17/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3394 - acc: 0.8562 - val_loss: 1.3193 - val_acc: 0.6365\n",
      "Epoch 18/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3414 - acc: 0.8559 - val_loss: 1.4961 - val_acc: 0.6251\n",
      "Epoch 19/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3371 - acc: 0.8528 - val_loss: 1.2898 - val_acc: 0.6385\n",
      "Epoch 20/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3394 - acc: 0.8572 - val_loss: 1.3914 - val_acc: 0.6323\n",
      "Epoch 21/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3426 - acc: 0.8472 - val_loss: 1.3589 - val_acc: 0.6354\n",
      "Epoch 22/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3350 - acc: 0.8595 - val_loss: 1.3575 - val_acc: 0.6365\n",
      "Epoch 23/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3379 - acc: 0.8567 - val_loss: 1.3613 - val_acc: 0.6344\n",
      "Epoch 24/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3342 - acc: 0.8570 - val_loss: 1.3371 - val_acc: 0.6365\n",
      "Epoch 25/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3318 - acc: 0.8608 - val_loss: 1.2853 - val_acc: 0.6385\n",
      "Epoch 26/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3337 - acc: 0.8631 - val_loss: 1.4236 - val_acc: 0.6323\n",
      "Epoch 27/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3437 - acc: 0.8570 - val_loss: 1.2964 - val_acc: 0.6375\n",
      "Epoch 28/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3371 - acc: 0.8601 - val_loss: 1.2543 - val_acc: 0.6406\n",
      "Epoch 29/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3335 - acc: 0.8639 - val_loss: 1.3880 - val_acc: 0.6354\n",
      "Epoch 30/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3425 - acc: 0.8505 - val_loss: 1.4553 - val_acc: 0.6292\n",
      "Epoch 31/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3263 - acc: 0.8634 - val_loss: 1.3651 - val_acc: 0.6365\n",
      "Epoch 32/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3263 - acc: 0.8662 - val_loss: 1.4052 - val_acc: 0.6354\n",
      "Epoch 33/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3364 - acc: 0.8544 - val_loss: 1.3915 - val_acc: 0.6365\n",
      "Epoch 34/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3315 - acc: 0.8616 - val_loss: 1.4056 - val_acc: 0.6365\n",
      "Epoch 35/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3356 - acc: 0.8590 - val_loss: 1.3538 - val_acc: 0.6365\n",
      "Epoch 36/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3366 - acc: 0.8526 - val_loss: 1.4926 - val_acc: 0.6272\n",
      "Epoch 37/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3314 - acc: 0.8621 - val_loss: 1.4790 - val_acc: 0.6282\n",
      "Epoch 38/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3297 - acc: 0.8644 - val_loss: 1.3464 - val_acc: 0.6365\n",
      "Epoch 39/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3365 - acc: 0.8562 - val_loss: 1.4005 - val_acc: 0.6365\n",
      "Epoch 40/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3299 - acc: 0.8598 - val_loss: 1.4953 - val_acc: 0.6272\n",
      "Epoch 41/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3340 - acc: 0.8564 - val_loss: 1.4492 - val_acc: 0.6334\n",
      "Epoch 42/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3381 - acc: 0.8580 - val_loss: 1.3905 - val_acc: 0.6365\n",
      "Epoch 43/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3243 - acc: 0.8603 - val_loss: 1.3603 - val_acc: 0.6365\n",
      "Epoch 44/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3283 - acc: 0.8598 - val_loss: 1.3598 - val_acc: 0.6365\n",
      "Epoch 45/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3361 - acc: 0.8562 - val_loss: 1.3505 - val_acc: 0.6365\n",
      "Epoch 46/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3214 - acc: 0.8662 - val_loss: 1.4460 - val_acc: 0.6354\n",
      "Epoch 47/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3327 - acc: 0.8575 - val_loss: 1.4654 - val_acc: 0.6334\n",
      "Epoch 48/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3284 - acc: 0.8662 - val_loss: 1.4025 - val_acc: 0.6344\n",
      "Epoch 49/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3231 - acc: 0.8649 - val_loss: 1.5003 - val_acc: 0.6313\n",
      "Epoch 50/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3320 - acc: 0.8577 - val_loss: 1.5449 - val_acc: 0.6262\n",
      "Epoch 51/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3274 - acc: 0.8668 - val_loss: 1.4267 - val_acc: 0.6344\n",
      "Epoch 52/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3298 - acc: 0.8562 - val_loss: 1.4409 - val_acc: 0.6344\n",
      "Epoch 53/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3193 - acc: 0.8706 - val_loss: 1.4999 - val_acc: 0.6323\n",
      "Epoch 54/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3185 - acc: 0.8649 - val_loss: 1.5432 - val_acc: 0.6292\n",
      "Epoch 55/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3270 - acc: 0.8582 - val_loss: 1.4521 - val_acc: 0.6344\n",
      "Epoch 56/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3217 - acc: 0.8593 - val_loss: 1.4551 - val_acc: 0.6344\n",
      "Epoch 57/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3138 - acc: 0.8670 - val_loss: 1.4728 - val_acc: 0.6344\n",
      "Epoch 58/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3277 - acc: 0.8644 - val_loss: 1.4676 - val_acc: 0.6344\n",
      "Epoch 59/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3290 - acc: 0.8582 - val_loss: 1.5145 - val_acc: 0.6313\n",
      "Epoch 60/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3230 - acc: 0.8647 - val_loss: 1.5487 - val_acc: 0.6292\n",
      "Epoch 61/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3301 - acc: 0.8585 - val_loss: 1.5487 - val_acc: 0.6292\n",
      "Epoch 62/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3295 - acc: 0.8603 - val_loss: 1.4380 - val_acc: 0.6354\n",
      "Epoch 63/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3231 - acc: 0.8626 - val_loss: 1.4311 - val_acc: 0.6365\n",
      "Epoch 64/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3277 - acc: 0.8570 - val_loss: 1.4570 - val_acc: 0.6344\n",
      "Epoch 65/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3225 - acc: 0.8698 - val_loss: 1.4925 - val_acc: 0.6334\n",
      "Epoch 66/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3280 - acc: 0.8668 - val_loss: 1.3878 - val_acc: 0.6395\n",
      "Epoch 67/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3250 - acc: 0.8585 - val_loss: 1.4771 - val_acc: 0.6344\n",
      "Epoch 68/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3197 - acc: 0.8613 - val_loss: 1.4178 - val_acc: 0.6375\n",
      "Epoch 69/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3349 - acc: 0.8503 - val_loss: 1.5020 - val_acc: 0.6323\n",
      "Epoch 70/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3177 - acc: 0.8665 - val_loss: 1.4826 - val_acc: 0.6344\n",
      "Epoch 71/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3242 - acc: 0.8655 - val_loss: 1.4651 - val_acc: 0.6365\n",
      "Epoch 72/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3201 - acc: 0.8660 - val_loss: 1.4276 - val_acc: 0.6375\n",
      "Epoch 73/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3247 - acc: 0.8598 - val_loss: 1.4253 - val_acc: 0.6375\n",
      "Epoch 74/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3143 - acc: 0.8626 - val_loss: 1.5188 - val_acc: 0.6323\n",
      "Epoch 75/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3203 - acc: 0.8680 - val_loss: 1.6265 - val_acc: 0.6262\n",
      "Epoch 76/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3178 - acc: 0.8673 - val_loss: 1.6183 - val_acc: 0.6272\n",
      "Epoch 77/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3265 - acc: 0.8580 - val_loss: 1.5515 - val_acc: 0.6313\n",
      "Epoch 78/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3195 - acc: 0.8670 - val_loss: 1.5795 - val_acc: 0.6292\n",
      "Epoch 79/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3107 - acc: 0.8722 - val_loss: 1.5422 - val_acc: 0.6323\n",
      "Epoch 80/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3188 - acc: 0.8655 - val_loss: 1.6301 - val_acc: 0.6282\n",
      "Epoch 81/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3163 - acc: 0.8680 - val_loss: 1.5747 - val_acc: 0.6282\n",
      "Epoch 82/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3238 - acc: 0.8608 - val_loss: 1.4711 - val_acc: 0.6365\n",
      "Epoch 83/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3187 - acc: 0.8629 - val_loss: 1.5296 - val_acc: 0.6323\n",
      "Epoch 84/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3190 - acc: 0.8639 - val_loss: 1.3729 - val_acc: 0.6395\n",
      "Epoch 85/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3130 - acc: 0.8740 - val_loss: 1.5473 - val_acc: 0.6323\n",
      "Epoch 86/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3158 - acc: 0.8680 - val_loss: 1.5085 - val_acc: 0.6334\n",
      "Epoch 87/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3193 - acc: 0.8662 - val_loss: 1.4251 - val_acc: 0.6375\n",
      "Epoch 88/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3119 - acc: 0.8678 - val_loss: 1.4238 - val_acc: 0.6375\n",
      "Epoch 89/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3145 - acc: 0.8639 - val_loss: 1.5351 - val_acc: 0.6334\n",
      "Epoch 90/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3255 - acc: 0.8557 - val_loss: 1.5106 - val_acc: 0.6354\n",
      "Epoch 91/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3062 - acc: 0.8737 - val_loss: 1.5281 - val_acc: 0.6344\n",
      "Epoch 92/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3181 - acc: 0.8660 - val_loss: 1.5656 - val_acc: 0.6303\n",
      "Epoch 93/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3229 - acc: 0.8570 - val_loss: 1.4432 - val_acc: 0.6375\n",
      "Epoch 94/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3125 - acc: 0.8706 - val_loss: 1.5094 - val_acc: 0.6365\n",
      "Epoch 95/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3155 - acc: 0.8729 - val_loss: 1.5494 - val_acc: 0.6334\n",
      "Epoch 96/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3182 - acc: 0.8668 - val_loss: 1.5301 - val_acc: 0.6344\n",
      "Epoch 97/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3163 - acc: 0.8680 - val_loss: 1.5067 - val_acc: 0.6354\n",
      "Epoch 98/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3130 - acc: 0.8649 - val_loss: 1.5943 - val_acc: 0.6292\n",
      "Epoch 99/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3132 - acc: 0.8701 - val_loss: 1.4797 - val_acc: 0.6385\n",
      "Epoch 100/100\n",
      "3880/3880 [==============================] - 37s 10ms/sample - loss: 0.3188 - acc: 0.8655 - val_loss: 1.5375 - val_acc: 0.6344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22dba3d0b08>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GoogLeNet_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = load_model('GoogLeNet_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3880 samples, validate on 971 samples\n",
      "Epoch 1/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3384 - acc: 0.8490 - val_loss: 1.3713 - val_acc: 0.6468\n",
      "Epoch 2/100\n",
      "3880/3880 [==============================] - 41s 10ms/sample - loss: 0.3272 - acc: 0.8595 - val_loss: 1.4358 - val_acc: 0.6447\n",
      "Epoch 3/100\n",
      "3880/3880 [==============================] - 41s 11ms/sample - loss: 0.3336 - acc: 0.8626 - val_loss: 1.3775 - val_acc: 0.6478\n",
      "Epoch 4/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3259 - acc: 0.8621 - val_loss: 1.4754 - val_acc: 0.6437\n",
      "Epoch 5/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3296 - acc: 0.8588 - val_loss: 1.2961 - val_acc: 0.6488\n",
      "Epoch 6/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3323 - acc: 0.8570 - val_loss: 1.5393 - val_acc: 0.6406\n",
      "Epoch 7/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3233 - acc: 0.8691 - val_loss: 1.3450 - val_acc: 0.6488\n",
      "Epoch 8/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3238 - acc: 0.8647 - val_loss: 1.4176 - val_acc: 0.6447\n",
      "Epoch 9/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3237 - acc: 0.8680 - val_loss: 1.5851 - val_acc: 0.6375\n",
      "Epoch 10/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3284 - acc: 0.8570 - val_loss: 1.4354 - val_acc: 0.6447\n",
      "Epoch 11/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3278 - acc: 0.8673 - val_loss: 1.3555 - val_acc: 0.6498\n",
      "Epoch 12/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3286 - acc: 0.8539 - val_loss: 1.3641 - val_acc: 0.6478\n",
      "Epoch 13/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3427 - acc: 0.8554 - val_loss: 1.3383 - val_acc: 0.6498\n",
      "Epoch 14/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3248 - acc: 0.8611 - val_loss: 1.3929 - val_acc: 0.6468\n",
      "Epoch 15/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3274 - acc: 0.8590 - val_loss: 1.4798 - val_acc: 0.6416\n",
      "Epoch 16/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3220 - acc: 0.8608 - val_loss: 1.4431 - val_acc: 0.6437\n",
      "Epoch 17/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3298 - acc: 0.8662 - val_loss: 1.4195 - val_acc: 0.6457\n",
      "Epoch 18/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3288 - acc: 0.8644 - val_loss: 1.2782 - val_acc: 0.6519\n",
      "Epoch 19/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3323 - acc: 0.8567 - val_loss: 1.3510 - val_acc: 0.6488\n",
      "Epoch 20/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3189 - acc: 0.8629 - val_loss: 1.5025 - val_acc: 0.6416\n",
      "Epoch 21/100\n",
      "3880/3880 [==============================] - 47s 12ms/sample - loss: 0.3241 - acc: 0.8608 - val_loss: 1.2357 - val_acc: 0.6529\n",
      "Epoch 22/100\n",
      "3880/3880 [==============================] - 47s 12ms/sample - loss: 0.3233 - acc: 0.8616 - val_loss: 1.5445 - val_acc: 0.6406\n",
      "Epoch 23/100\n",
      "3880/3880 [==============================] - 48s 12ms/sample - loss: 0.3256 - acc: 0.8631 - val_loss: 1.4325 - val_acc: 0.6437\n",
      "Epoch 24/100\n",
      "3880/3880 [==============================] - 48s 12ms/sample - loss: 0.3172 - acc: 0.8660 - val_loss: 1.2612 - val_acc: 0.6509\n",
      "Epoch 25/100\n",
      "3880/3880 [==============================] - 47s 12ms/sample - loss: 0.3234 - acc: 0.8698 - val_loss: 1.4767 - val_acc: 0.6426\n",
      "Epoch 26/100\n",
      "3880/3880 [==============================] - 47s 12ms/sample - loss: 0.3188 - acc: 0.8621 - val_loss: 1.5067 - val_acc: 0.6406\n",
      "Epoch 27/100\n",
      "3880/3880 [==============================] - 47s 12ms/sample - loss: 0.3111 - acc: 0.8735 - val_loss: 1.3332 - val_acc: 0.6509\n",
      "Epoch 28/100\n",
      "3880/3880 [==============================] - 47s 12ms/sample - loss: 0.3252 - acc: 0.8608 - val_loss: 1.4283 - val_acc: 0.6447\n",
      "Epoch 29/100\n",
      "3880/3880 [==============================] - 44s 11ms/sample - loss: 0.3163 - acc: 0.8657 - val_loss: 1.3932 - val_acc: 0.6478\n",
      "Epoch 30/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3265 - acc: 0.8626 - val_loss: 1.4336 - val_acc: 0.6437\n",
      "Epoch 31/100\n",
      "3880/3880 [==============================] - 44s 11ms/sample - loss: 0.3322 - acc: 0.8554 - val_loss: 1.3232 - val_acc: 0.6498\n",
      "Epoch 32/100\n",
      "3880/3880 [==============================] - 48s 12ms/sample - loss: 0.3199 - acc: 0.8657 - val_loss: 1.4476 - val_acc: 0.6437\n",
      "Epoch 33/100\n",
      "3880/3880 [==============================] - 48s 12ms/sample - loss: 0.3222 - acc: 0.8606 - val_loss: 1.3995 - val_acc: 0.6478\n",
      "Epoch 34/100\n",
      "3880/3880 [==============================] - 48s 12ms/sample - loss: 0.3088 - acc: 0.8753 - val_loss: 1.4059 - val_acc: 0.6468\n",
      "Epoch 35/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3161 - acc: 0.8670 - val_loss: 1.3508 - val_acc: 0.6498\n",
      "Epoch 36/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3102 - acc: 0.8647 - val_loss: 1.4669 - val_acc: 0.6437\n",
      "Epoch 37/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3210 - acc: 0.8644 - val_loss: 1.5030 - val_acc: 0.6437\n",
      "Epoch 38/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3116 - acc: 0.8727 - val_loss: 1.3570 - val_acc: 0.6488\n",
      "Epoch 39/100\n",
      "3880/3880 [==============================] - 43s 11ms/sample - loss: 0.3081 - acc: 0.8711 - val_loss: 1.4103 - val_acc: 0.6457\n",
      "Epoch 40/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3171 - acc: 0.8655 - val_loss: 1.4070 - val_acc: 0.6457\n",
      "Epoch 41/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3270 - acc: 0.8673 - val_loss: 1.4763 - val_acc: 0.6437\n",
      "Epoch 42/100\n",
      "3880/3880 [==============================] - 44s 11ms/sample - loss: 0.3193 - acc: 0.8668 - val_loss: 1.4604 - val_acc: 0.6447\n",
      "Epoch 43/100\n",
      "3880/3880 [==============================] - 42s 11ms/sample - loss: 0.3103 - acc: 0.8662 - val_loss: 1.4247 - val_acc: 0.6468\n",
      "Epoch 44/100\n",
      "3880/3880 [==============================] - 40s 10ms/sample - loss: 0.3115 - acc: 0.8688 - val_loss: 1.5830 - val_acc: 0.6437\n",
      "Epoch 45/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3238 - acc: 0.8686 - val_loss: 1.3325 - val_acc: 0.6498\n",
      "Epoch 46/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3117 - acc: 0.8680 - val_loss: 1.4338 - val_acc: 0.6457\n",
      "Epoch 47/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3188 - acc: 0.8647 - val_loss: 1.4420 - val_acc: 0.6468\n",
      "Epoch 48/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3119 - acc: 0.8729 - val_loss: 1.4339 - val_acc: 0.6457\n",
      "Epoch 49/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3116 - acc: 0.8716 - val_loss: 1.5038 - val_acc: 0.6457\n",
      "Epoch 50/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3096 - acc: 0.8683 - val_loss: 1.5007 - val_acc: 0.6457\n",
      "Epoch 51/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3073 - acc: 0.8732 - val_loss: 1.4456 - val_acc: 0.6468\n",
      "Epoch 52/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3136 - acc: 0.8773 - val_loss: 1.5166 - val_acc: 0.6447\n",
      "Epoch 53/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3178 - acc: 0.8647 - val_loss: 1.3138 - val_acc: 0.6509\n",
      "Epoch 54/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3077 - acc: 0.8686 - val_loss: 1.4899 - val_acc: 0.6468\n",
      "Epoch 55/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3134 - acc: 0.8714 - val_loss: 1.3826 - val_acc: 0.6488\n",
      "Epoch 56/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3095 - acc: 0.8760 - val_loss: 1.3545 - val_acc: 0.6488\n",
      "Epoch 57/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3131 - acc: 0.8714 - val_loss: 1.4913 - val_acc: 0.6478\n",
      "Epoch 58/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3088 - acc: 0.8709 - val_loss: 1.3917 - val_acc: 0.6468\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3222 - acc: 0.8670 - val_loss: 1.6115 - val_acc: 0.6406\n",
      "Epoch 60/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3246 - acc: 0.8608 - val_loss: 1.3514 - val_acc: 0.6498\n",
      "Epoch 61/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3085 - acc: 0.8719 - val_loss: 1.4661 - val_acc: 0.6468\n",
      "Epoch 62/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3076 - acc: 0.8737 - val_loss: 1.4902 - val_acc: 0.6468\n",
      "Epoch 63/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3066 - acc: 0.8722 - val_loss: 1.5150 - val_acc: 0.6457\n",
      "Epoch 64/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3060 - acc: 0.8683 - val_loss: 1.4071 - val_acc: 0.6468\n",
      "Epoch 65/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3116 - acc: 0.8724 - val_loss: 1.3411 - val_acc: 0.6498\n",
      "Epoch 66/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3217 - acc: 0.8590 - val_loss: 1.4550 - val_acc: 0.6457\n",
      "Epoch 67/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3148 - acc: 0.8686 - val_loss: 1.3024 - val_acc: 0.6519\n",
      "Epoch 68/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3162 - acc: 0.8662 - val_loss: 1.5282 - val_acc: 0.6468\n",
      "Epoch 69/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3176 - acc: 0.8675 - val_loss: 1.4698 - val_acc: 0.6457\n",
      "Epoch 70/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3184 - acc: 0.8626 - val_loss: 1.3848 - val_acc: 0.6478\n",
      "Epoch 71/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3108 - acc: 0.8652 - val_loss: 1.3400 - val_acc: 0.6498\n",
      "Epoch 72/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3042 - acc: 0.8771 - val_loss: 1.5062 - val_acc: 0.6457\n",
      "Epoch 73/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3091 - acc: 0.8660 - val_loss: 1.5520 - val_acc: 0.6447\n",
      "Epoch 74/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3082 - acc: 0.8722 - val_loss: 1.5766 - val_acc: 0.6447\n",
      "Epoch 75/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3144 - acc: 0.8670 - val_loss: 1.3450 - val_acc: 0.6498\n",
      "Epoch 76/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3049 - acc: 0.8686 - val_loss: 1.3537 - val_acc: 0.6498\n",
      "Epoch 77/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3107 - acc: 0.8704 - val_loss: 1.4031 - val_acc: 0.6468\n",
      "Epoch 78/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3002 - acc: 0.8716 - val_loss: 1.4335 - val_acc: 0.6457\n",
      "Epoch 79/100\n",
      "3880/3880 [==============================] - 39s 10ms/sample - loss: 0.3072 - acc: 0.8755 - val_loss: 1.5138 - val_acc: 0.6457\n",
      "Epoch 80/100\n",
      "3880/3880 [==============================] - 39s 10ms/sample - loss: 0.3100 - acc: 0.8719 - val_loss: 1.3918 - val_acc: 0.6478\n",
      "Epoch 81/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3015 - acc: 0.8776 - val_loss: 1.6330 - val_acc: 0.6375\n",
      "Epoch 82/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3101 - acc: 0.8724 - val_loss: 1.4124 - val_acc: 0.6468\n",
      "Epoch 83/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3030 - acc: 0.8778 - val_loss: 1.2913 - val_acc: 0.6540\n",
      "Epoch 84/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.2909 - acc: 0.8786 - val_loss: 1.4638 - val_acc: 0.6457\n",
      "Epoch 85/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3062 - acc: 0.8675 - val_loss: 1.3498 - val_acc: 0.6509\n",
      "Epoch 86/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3000 - acc: 0.8737 - val_loss: 1.4463 - val_acc: 0.6468\n",
      "Epoch 87/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3065 - acc: 0.8706 - val_loss: 1.4825 - val_acc: 0.6468\n",
      "Epoch 88/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3066 - acc: 0.8706 - val_loss: 1.3981 - val_acc: 0.6478\n",
      "Epoch 89/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3087 - acc: 0.8722 - val_loss: 1.3138 - val_acc: 0.6519\n",
      "Epoch 90/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.2992 - acc: 0.8753 - val_loss: 1.4506 - val_acc: 0.6468\n",
      "Epoch 91/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3051 - acc: 0.8745 - val_loss: 1.3992 - val_acc: 0.6488\n",
      "Epoch 92/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3065 - acc: 0.8652 - val_loss: 1.2737 - val_acc: 0.6540\n",
      "Epoch 93/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3163 - acc: 0.8619 - val_loss: 1.4836 - val_acc: 0.6468\n",
      "Epoch 94/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3171 - acc: 0.8639 - val_loss: 1.4473 - val_acc: 0.6468\n",
      "Epoch 95/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3071 - acc: 0.8742 - val_loss: 1.4589 - val_acc: 0.6478\n",
      "Epoch 96/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3004 - acc: 0.8750 - val_loss: 1.4187 - val_acc: 0.6478\n",
      "Epoch 97/100\n",
      "3880/3880 [==============================] - 40s 10ms/sample - loss: 0.3077 - acc: 0.8665 - val_loss: 1.4419 - val_acc: 0.6478\n",
      "Epoch 98/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3020 - acc: 0.8753 - val_loss: 1.3417 - val_acc: 0.6509\n",
      "Epoch 99/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3042 - acc: 0.8732 - val_loss: 1.4378 - val_acc: 0.6478\n",
      "Epoch 100/100\n",
      "3880/3880 [==============================] - 38s 10ms/sample - loss: 0.3073 - acc: 0.8696 - val_loss: 1.3642 - val_acc: 0.6509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x234c55b4048>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GoogLeNet_300.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_images_from_folder_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testt = np.array([i[0] for i in test]).reshape(-1,224,224,3)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testt = np.array([i[1] for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_labels=np.argmax(y_testt, axis=1)\n",
    "rounded_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4641824855744463, 0.5691824]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_testt, y_testt, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[334,   4],\n",
       "       [270,  28]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(X_testt)\n",
    "prediction = np.argmax(prediction,axis=1)\n",
    "confusion_matrix(rounded_labels, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

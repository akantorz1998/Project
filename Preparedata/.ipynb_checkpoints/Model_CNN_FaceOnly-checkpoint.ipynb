{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rotation_range=0.5,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14188 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'E:\\\\Drowsiness\\\\train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alert': 0, 'drowsy': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3971 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'E:\\\\Drowsiness\\\\val',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alert': 0, 'drowsy': 1}\n"
     ]
    }
   ],
   "source": [
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'E:\\\\Drowsiness\\\\test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drowsiness = [0,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data = []\n",
    "labels = []\n",
    "image_paths = 'E:/Drowsiness/dataset/face_image/'\n",
    "\n",
    "for Respondent in range(50):\n",
    "    for i in range(20):\n",
    "        for drows in drowsiness:\n",
    "            name_img = str(Respondent) +'_'+str(i+1)+'_'+str(drows)\n",
    "            image = cv2.imread(image_paths+name_img+'.jpg')\n",
    "            \n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, (100, 100))\n",
    "                cv2.imshow('image',image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "                \n",
    "                if drows == 10:\n",
    "                    drows = 1\n",
    "                labels.append(drows)\n",
    "                data.append(image)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_test = []\n",
    "y_test = []\n",
    "image_paths = 'E:/Drowsiness/dataset/face_image/'\n",
    "\n",
    "for Respondent in range(50,61):\n",
    "    for i in range(200):\n",
    "        for drows in drowsiness:\n",
    "            name_img = str(Respondent) +'_'+str(i+1)+'_'+str(drows)\n",
    "            image = cv2.imread(image_paths+name_img+'.jpg')\n",
    "            \n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, (150, 150))\n",
    "                cv2.imshow('image',image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "                \n",
    "                if drows == 10:\n",
    "                    drows = 1\n",
    "                y_test.append(drows)\n",
    "                X_test.append(image)\n",
    "cv2.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "X_test = []\n",
    "y_test = []\n",
    "image_paths = 'E:/Drowsiness/test/alert/'\n",
    "\n",
    "for Respondent in range(0,61):\n",
    "    for i in range(200):\n",
    "        for drows in drowsiness:\n",
    "            name_img = str(Respondent) +'_'+str(i+1)+'_'+str(drows)\n",
    "            image = cv2.imread(image_paths+name_img+'.jpg')\n",
    "            \n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, (150, 150))\n",
    "                cv2.imshow('image',image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "                \n",
    "                if drows == 10:\n",
    "                    drows = 1\n",
    "                y_test.append(drows)\n",
    "                X_test.append(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = 'E:/Drowsiness/test/drowsy/'\n",
    "\n",
    "for Respondent in range(0,61):\n",
    "    for i in range(200):\n",
    "        for drows in drowsiness:\n",
    "            name_img = str(Respondent) +'_'+str(i+1)+'_'+str(drows)\n",
    "            image = cv2.imread(image_paths+name_img+'.jpg')\n",
    "            \n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, (150, 150))\n",
    "                cv2.imshow('image',image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "                \n",
    "                if drows == 10:\n",
    "                    drows = 1\n",
    "                y_test.append(drows)\n",
    "                X_test.append(image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_train = np.array(data)\n",
    "y_train = np.array(labels)\n",
    "data = []\n",
    "labels = []\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 150, 150, 3)\n",
      "(1386,)\n"
     ]
    }
   ],
   "source": [
    "#print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation\n",
    "#flip\n",
    "#newArray = X_train\n",
    "data1 = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    flip = np.fliplr(X_train[i])\n",
    "    data1.append(flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.array(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.append(X_train,data1,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[799])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.append(y_train,y_train,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(7857):\n",
    "    if y_train[i] != y_train[7857+i]:\n",
    "        print(y_train[i])\n",
    "        print(y_train[7857+i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotation\n",
    "import skimage\n",
    "import skimage.transform\n",
    "# Placeholders: 'x' = A single image, 'y' = A batch of images\n",
    "# 'k' denotes the number of 90 degree anticlockwise rotations\n",
    "shape = [100, 100, 3]\n",
    "x = tf.placeholder(dtype = tf.float32, shape = shape)\n",
    "rot_90 = tf.image.rot90(X_train[0], k=1)\n",
    "rot_180 = tf.image.rot90(X_train[0], k=2)\n",
    "# To rotate in any angle. In the example below, 'angles' is in radians\n",
    "shape = [1, 100, 100, 3]\n",
    "y = tf.placeholder(dtype = tf.float32, shape = shape)\n",
    "rot_tf_180 = tf.contrib.image.rotate(y, angles=3.1415)\n",
    "# Scikit-Image. 'angle' = Degrees. 'img' = Input Image\n",
    "# For details about 'mode', checkout the interpolation section below.\n",
    "rot = skimage.transform.rotate(X_train[0], angle=45, mode='reflect')\n",
    "rot1 = skimage.transform.rotate(X_train[0], angle=315, mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    rot = skimage.transform.rotate(X_train[0], angle=45, mode='reflect')\n",
    "    rot2 = skimage.transform.rotate(X_train[0], angle=315, mode='reflect')\n",
    "    data1.append(rot)\n",
    "    data2.append(rot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data1[799])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data2[799])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.array(data1)\n",
    "data2 = np.array(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.append(X_train,data1,axis = 0)\n",
    "y_train_t = y_train\n",
    "y_train = np.append(y_train,y_train,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.append(X_train,data2,axis = 0)\n",
    "y_train = np.append(y_train,y_train_t,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = []\n",
    "data2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, null, y_test, null = train_test_split(X_test, y_test, test_size=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1135b1634298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import to_categorical\n",
    "#y_train = to_categorical(y_train, 2)\n",
    "##y_test = to_categorical(y_test, 2)\n",
    "#y_val = to_categorical(y_val, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])\n",
    "print(X_test[0])\n",
    "print(X_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel = Sequential()\\nmodel.add(Conv2D(128,(3,3),input_shape=(150,150,3),activation=\"relu\"))\\nmodel.add(MaxPooling2D((2,2)))\\nmodel.add(Conv2D(64,(3,3),activation=\"relu\"))\\nmodel.add(MaxPooling2D((2,2)))\\nmodel.add(Dropout(.4))\\nmodel.add(Conv2D(32,(3,3),activation=\"relu\"))\\nmodel.add(MaxPooling2D((2,2)))\\nmodel.add(Flatten())\\nmodel.add(Dense(256,activation=\"relu\"))\\nmodel.add(Dropout(.4))\\nmodel.add(Dense(128,activation=\"relu\"))\\nmodel.add(Dropout(.4))\\nmodel.add(Dense(32,activation=\"relu\"))\\nmodel.add(Dropout(.4))\\nmodel.add(Dense(1,activation=\"sigmoid\"))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.layers.core import Dense, Flatten,Activation,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Create Sequential Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (4, 4), input_shape=(100, 100, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create Sequential Model\n",
    "model = Sequential()\n",
    "# Layer 1: Convolutional Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(150,150,3), activation='relu',))\n",
    "# Layer 2: Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "# Layer 3: Convolutional Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(150,150,3), activation='relu',))\n",
    "# Layer 4: Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "# Layer 5: Flatten Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=(150,150,3), activation='relu',))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Layer 6: Dense Layer (Hidden Layer)\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# Layer 7: Dense Layer (Output Layer)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128,(3,3),input_shape=(150,150,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Conv2D(32,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 553,953\n",
      "Trainable params: 553,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# COMPILE\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 0.3457 - accuracy: 0.8291 - val_loss: 1.1680 - val_accuracy: 0.5574\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.0775 - accuracy: 0.9726 - val_loss: 2.9567 - val_accuracy: 0.5897\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 4.7444 - val_accuracy: 0.5765\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 1.9227 - val_accuracy: 0.6279\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 165s 165ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 6.1033 - val_accuracy: 0.6520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 1.7891 - val_accuracy: 0.6211\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 2.5013 - val_accuracy: 0.6209\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 1.6362 - val_accuracy: 0.6575\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 3.3810 - val_accuracy: 0.5820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 164s 164ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 1.2938 - val_accuracy: 0.5579\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "#model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))\n",
    "#3model.save('CNN_Model')\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=200)\n",
    "\n",
    "\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "#early_stop = EarlyStopping(monitor='val_loss', patience=4)\n",
    "#model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), callbacks=[early_stop])\n",
    "model.save('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.167990</td>\n",
       "      <td>0.557369</td>\n",
       "      <td>0.345848</td>\n",
       "      <td>0.829148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.956728</td>\n",
       "      <td>0.589719</td>\n",
       "      <td>0.077476</td>\n",
       "      <td>0.972559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.744418</td>\n",
       "      <td>0.576519</td>\n",
       "      <td>0.044850</td>\n",
       "      <td>0.984762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.922730</td>\n",
       "      <td>0.627878</td>\n",
       "      <td>0.031777</td>\n",
       "      <td>0.989049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.103310</td>\n",
       "      <td>0.652003</td>\n",
       "      <td>0.024068</td>\n",
       "      <td>0.991990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.789097</td>\n",
       "      <td>0.621096</td>\n",
       "      <td>0.022073</td>\n",
       "      <td>0.992674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.501341</td>\n",
       "      <td>0.620940</td>\n",
       "      <td>0.019494</td>\n",
       "      <td>0.993836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.636218</td>\n",
       "      <td>0.657511</td>\n",
       "      <td>0.016677</td>\n",
       "      <td>0.994962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.380966</td>\n",
       "      <td>0.581993</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>0.994897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.293769</td>\n",
       "      <td>0.557868</td>\n",
       "      <td>0.012003</td>\n",
       "      <td>0.996123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_accuracy      loss  accuracy\n",
       "0  1.167990      0.557369  0.345848  0.829148\n",
       "1  2.956728      0.589719  0.077476  0.972559\n",
       "2  4.744418      0.576519  0.044850  0.984762\n",
       "3  1.922730      0.627878  0.031777  0.989049\n",
       "4  6.103310      0.652003  0.024068  0.991990\n",
       "5  1.789097      0.621096  0.022073  0.992674\n",
       "6  2.501341      0.620940  0.019494  0.993836\n",
       "7  1.636218      0.657511  0.016677  0.994962\n",
       "8  3.380966      0.581993  0.015577  0.994897\n",
       "9  1.293769      0.557868  0.012003  0.996123"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bf213f1e48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bf214e7f08>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.2555289934207865, 0.17676767706871033]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.24      0.25       792\n",
      "           1       0.08      0.09      0.09       594\n",
      "\n",
      "    accuracy                           0.18      1386\n",
      "   macro avg       0.17      0.17      0.17      1386\n",
      "weighted avg       0.18      0.18      0.18      1386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "prediction = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[192, 600],\n",
       "       [541,  53]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "prediction = model.predict_classes(X_test)\n",
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 553,953\n",
      "Trainable params: 553,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[192, 600],\n",
       "       [541,  53]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "prediction = model.predict_classes(X_test)\n",
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 2.3382 - val_accuracy: 0.6627\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 2.2761 - val_accuracy: 0.6241\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.4944 - val_accuracy: 0.6308\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 172s 172ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 1.7043 - val_accuracy: 0.6662\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 172s 172ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 1.0141 - val_accuracy: 0.5881\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 172s 172ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 4.0689 - val_accuracy: 0.5863\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 172s 172ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 3.2886 - val_accuracy: 0.5643\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 172s 172ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 3.9907 - val_accuracy: 0.6010\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 2.5309 - val_accuracy: 0.6886\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 2.5889 - val_accuracy: 0.5571\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=200)\n",
    "model.save('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[648, 144],\n",
       "       [593,   1]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(X_test)\n",
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.114040736947276, 0.4682539701461792]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "model = load_model('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 553,953\n",
      "Trainable params: 553,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 1.9451 - val_accuracy: 0.5990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 3.5257 - val_accuracy: 0.5315\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 2.0374 - val_accuracy: 0.5910\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 1.7638 - val_accuracy: 0.6009\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 172s 172ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 3.2175 - val_accuracy: 0.5102\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 1.6454 - val_accuracy: 0.5811\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 2.7059 - val_accuracy: 0.5889\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 1.9958 - val_accuracy: 0.6671\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 170s 170ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 3.5758 - val_accuracy: 0.6550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 3.0541 - val_accuracy: 0.5984\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=200)\n",
    "model.save('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 19, 773],\n",
       "       [450, 144]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(X_test)\n",
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.481940216488308, 0.11760462075471878]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "model = load_model('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 2.6647 - val_accuracy: 0.5459\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 3.3849 - val_accuracy: 0.5069\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.2645 - val_accuracy: 0.6081\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 3.2969 - val_accuracy: 0.6834\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 177s 177ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 4.0866 - val_accuracy: 0.6406\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 2.9237 - val_accuracy: 0.5323\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 182s 182ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 2.0224 - val_accuracy: 0.6290\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 5.6090 - val_accuracy: 0.5707\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 3.6399 - val_accuracy: 0.5173\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 1.9522 - val_accuracy: 0.5738\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=200)\n",
    "model.save('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.5653044554750295, 0.12265512347221375]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2, 790],\n",
       "       [426, 168]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(X_test)\n",
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "model = load_model('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 180s 180ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 2.8304 - val_accuracy: 0.6282\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 4.6002 - val_accuracy: 0.5378\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 3.8792 - val_accuracy: 0.5740\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 181s 181ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 4.2021 - val_accuracy: 0.5957\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 181s 181ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 7.0648 - val_accuracy: 0.6641\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 181s 181ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 3.6430 - val_accuracy: 0.6123\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 185s 185ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 4.2164 - val_accuracy: 0.5875\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 182s 182ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 1.6783 - val_accuracy: 0.6021\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 181s 181ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 2.9233 - val_accuracy: 0.6820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 1.9258 - val_accuracy: 0.6019\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=200)\n",
    "model.save('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 47, 745],\n",
       "       [494, 100]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(X_test)\n",
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "model = load_model('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 259s 173ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 2.8211 - val_accuracy: 0.5833\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 256s 170ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 2.4408 - val_accuracy: 0.6258\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 257s 172ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 9.6230 - val_accuracy: 0.6021\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 259s 172ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 2.2642 - val_accuracy: 0.6862\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 254s 170ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 11.8069 - val_accuracy: 0.5628\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 256s 170ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 2.0196 - val_accuracy: 0.6528\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 257s 171ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 4.0707 - val_accuracy: 0.7099\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 256s 170ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.9960 - val_accuracy: 0.6183\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 256s 170ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 1.6081 - val_accuracy: 0.6481\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 256s 171ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 1.2671 - val_accuracy: 0.6984\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 254s 169ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 3.6342 - val_accuracy: 0.6743\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 250s 167ms/step - loss: 5.9929e-04 - accuracy: 0.9997 - val_loss: 2.8009 - val_accuracy: 0.5965\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 250s 167ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 3.3048 - val_accuracy: 0.6241\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 249s 166ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 2.6016 - val_accuracy: 0.6668\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 249s 166ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 6.4288 - val_accuracy: 0.6072\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 249s 166ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 3.5333 - val_accuracy: 0.6508\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 255s 170ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 3.0529 - val_accuracy: 0.5126\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 257s 171ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 3.4755 - val_accuracy: 0.6068\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 256s 170ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 3.1950 - val_accuracy: 0.5585\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 260s 173ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 1.3461 - val_accuracy: 0.6056\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1500,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=200),\n",
    "model.save('CNN_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.59224305834089, 0.22077922523021698]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[269, 523],\n",
       "       [557,  37]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(X_test)\n",
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

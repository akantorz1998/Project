{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/Data/totalwithmaininfo.csv',sep=',')\n",
    "df = df.drop(df.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>EAR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>Circularity</th>\n",
       "      <th>MOE</th>\n",
       "      <th>EAR_N</th>\n",
       "      <th>MAR_N</th>\n",
       "      <th>Circularity_N</th>\n",
       "      <th>MOE_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.986514</td>\n",
       "      <td>0.450053</td>\n",
       "      <td>3.122874</td>\n",
       "      <td>-0.871732</td>\n",
       "      <td>-0.022238</td>\n",
       "      <td>-1.102540</td>\n",
       "      <td>1.043034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.320060</td>\n",
       "      <td>0.967440</td>\n",
       "      <td>0.497489</td>\n",
       "      <td>3.022686</td>\n",
       "      <td>-0.219925</td>\n",
       "      <td>-0.988696</td>\n",
       "      <td>0.254111</td>\n",
       "      <td>-0.950539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.328431</td>\n",
       "      <td>1.006906</td>\n",
       "      <td>0.518270</td>\n",
       "      <td>3.065808</td>\n",
       "      <td>1.091657</td>\n",
       "      <td>1.010933</td>\n",
       "      <td>0.848429</td>\n",
       "      <td>-0.092496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.351223</td>\n",
       "      <td>1.102950</td>\n",
       "      <td>0.536187</td>\n",
       "      <td>3.140313</td>\n",
       "      <td>4.662748</td>\n",
       "      <td>5.877299</td>\n",
       "      <td>1.360857</td>\n",
       "      <td>1.390040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.337345</td>\n",
       "      <td>1.094224</td>\n",
       "      <td>0.504254</td>\n",
       "      <td>3.243631</td>\n",
       "      <td>2.488390</td>\n",
       "      <td>5.435149</td>\n",
       "      <td>0.447582</td>\n",
       "      <td>3.445910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>10</td>\n",
       "      <td>0.275401</td>\n",
       "      <td>1.182630</td>\n",
       "      <td>0.414005</td>\n",
       "      <td>4.294205</td>\n",
       "      <td>-1.117401</td>\n",
       "      <td>4.190975</td>\n",
       "      <td>-0.958109</td>\n",
       "      <td>2.483317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9596</th>\n",
       "      <td>10</td>\n",
       "      <td>0.204631</td>\n",
       "      <td>1.189241</td>\n",
       "      <td>0.291487</td>\n",
       "      <td>5.811628</td>\n",
       "      <td>-2.777285</td>\n",
       "      <td>4.387865</td>\n",
       "      <td>-3.855693</td>\n",
       "      <td>6.131075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>10</td>\n",
       "      <td>0.290996</td>\n",
       "      <td>1.110189</td>\n",
       "      <td>0.398633</td>\n",
       "      <td>3.815133</td>\n",
       "      <td>-0.751634</td>\n",
       "      <td>2.033375</td>\n",
       "      <td>-1.321658</td>\n",
       "      <td>1.331666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9598</th>\n",
       "      <td>10</td>\n",
       "      <td>0.301910</td>\n",
       "      <td>1.143009</td>\n",
       "      <td>0.420446</td>\n",
       "      <td>3.785924</td>\n",
       "      <td>-0.495647</td>\n",
       "      <td>3.010903</td>\n",
       "      <td>-0.805777</td>\n",
       "      <td>1.261450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>10</td>\n",
       "      <td>0.250010</td>\n",
       "      <td>1.143407</td>\n",
       "      <td>0.439890</td>\n",
       "      <td>4.573453</td>\n",
       "      <td>-1.712957</td>\n",
       "      <td>3.022742</td>\n",
       "      <td>-0.345922</td>\n",
       "      <td>3.154605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9600 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Y       EAR       MAR  Circularity       MOE     EAR_N     MAR_N  \\\n",
       "0      0  0.315900  0.986514     0.450053  3.122874 -0.871732 -0.022238   \n",
       "1      0  0.320060  0.967440     0.497489  3.022686 -0.219925 -0.988696   \n",
       "2      0  0.328431  1.006906     0.518270  3.065808  1.091657  1.010933   \n",
       "3      0  0.351223  1.102950     0.536187  3.140313  4.662748  5.877299   \n",
       "4      0  0.337345  1.094224     0.504254  3.243631  2.488390  5.435149   \n",
       "...   ..       ...       ...          ...       ...       ...       ...   \n",
       "9595  10  0.275401  1.182630     0.414005  4.294205 -1.117401  4.190975   \n",
       "9596  10  0.204631  1.189241     0.291487  5.811628 -2.777285  4.387865   \n",
       "9597  10  0.290996  1.110189     0.398633  3.815133 -0.751634  2.033375   \n",
       "9598  10  0.301910  1.143009     0.420446  3.785924 -0.495647  3.010903   \n",
       "9599  10  0.250010  1.143407     0.439890  4.573453 -1.712957  3.022742   \n",
       "\n",
       "      Circularity_N     MOE_N  \n",
       "0         -1.102540  1.043034  \n",
       "1          0.254111 -0.950539  \n",
       "2          0.848429 -0.092496  \n",
       "3          1.360857  1.390040  \n",
       "4          0.447582  3.445910  \n",
       "...             ...       ...  \n",
       "9595      -0.958109  2.483317  \n",
       "9596      -3.855693  6.131075  \n",
       "9597      -1.321658  1.331666  \n",
       "9598      -0.805777  1.261450  \n",
       "9599      -0.345922  3.154605  \n",
       "\n",
       "[9600 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Y != 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percentage = 7/8\n",
    "train_index = int(len(df)*train_percentage)\n",
    "test_index = len(df)-train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:train_index]\n",
    "df_test = df[-test_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>EAR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>Circularity</th>\n",
       "      <th>MOE</th>\n",
       "      <th>EAR_N</th>\n",
       "      <th>MAR_N</th>\n",
       "      <th>Circularity_N</th>\n",
       "      <th>MOE_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8400</th>\n",
       "      <td>0</td>\n",
       "      <td>0.346804</td>\n",
       "      <td>1.022771</td>\n",
       "      <td>0.479602</td>\n",
       "      <td>2.949136</td>\n",
       "      <td>0.557304</td>\n",
       "      <td>-0.570294</td>\n",
       "      <td>0.593287</td>\n",
       "      <td>-0.750118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8401</th>\n",
       "      <td>0</td>\n",
       "      <td>0.273821</td>\n",
       "      <td>1.022298</td>\n",
       "      <td>0.405698</td>\n",
       "      <td>3.733454</td>\n",
       "      <td>-1.154471</td>\n",
       "      <td>-0.584378</td>\n",
       "      <td>-1.154553</td>\n",
       "      <td>1.135317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8402</th>\n",
       "      <td>0</td>\n",
       "      <td>0.348503</td>\n",
       "      <td>1.080686</td>\n",
       "      <td>0.478248</td>\n",
       "      <td>3.100938</td>\n",
       "      <td>0.597167</td>\n",
       "      <td>1.154672</td>\n",
       "      <td>0.561266</td>\n",
       "      <td>-0.385199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8403</th>\n",
       "      <td>0</td>\n",
       "      <td>0.282846</td>\n",
       "      <td>1.051722</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>3.718361</td>\n",
       "      <td>-0.942799</td>\n",
       "      <td>0.292007</td>\n",
       "      <td>-0.448633</td>\n",
       "      <td>1.099036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8404</th>\n",
       "      <td>0</td>\n",
       "      <td>0.363169</td>\n",
       "      <td>1.057844</td>\n",
       "      <td>0.528093</td>\n",
       "      <td>2.912813</td>\n",
       "      <td>0.941154</td>\n",
       "      <td>0.474336</td>\n",
       "      <td>1.740125</td>\n",
       "      <td>-0.837434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>10</td>\n",
       "      <td>0.275401</td>\n",
       "      <td>1.182630</td>\n",
       "      <td>0.414005</td>\n",
       "      <td>4.294205</td>\n",
       "      <td>-1.117401</td>\n",
       "      <td>4.190975</td>\n",
       "      <td>-0.958109</td>\n",
       "      <td>2.483317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9596</th>\n",
       "      <td>10</td>\n",
       "      <td>0.204631</td>\n",
       "      <td>1.189241</td>\n",
       "      <td>0.291487</td>\n",
       "      <td>5.811628</td>\n",
       "      <td>-2.777285</td>\n",
       "      <td>4.387865</td>\n",
       "      <td>-3.855693</td>\n",
       "      <td>6.131075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>10</td>\n",
       "      <td>0.290996</td>\n",
       "      <td>1.110189</td>\n",
       "      <td>0.398633</td>\n",
       "      <td>3.815133</td>\n",
       "      <td>-0.751634</td>\n",
       "      <td>2.033375</td>\n",
       "      <td>-1.321658</td>\n",
       "      <td>1.331666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9598</th>\n",
       "      <td>10</td>\n",
       "      <td>0.301910</td>\n",
       "      <td>1.143009</td>\n",
       "      <td>0.420446</td>\n",
       "      <td>3.785924</td>\n",
       "      <td>-0.495647</td>\n",
       "      <td>3.010903</td>\n",
       "      <td>-0.805777</td>\n",
       "      <td>1.261450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>10</td>\n",
       "      <td>0.250010</td>\n",
       "      <td>1.143407</td>\n",
       "      <td>0.439890</td>\n",
       "      <td>4.573453</td>\n",
       "      <td>-1.712957</td>\n",
       "      <td>3.022742</td>\n",
       "      <td>-0.345922</td>\n",
       "      <td>3.154605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Y       EAR       MAR  Circularity       MOE     EAR_N     MAR_N  \\\n",
       "8400   0  0.346804  1.022771     0.479602  2.949136  0.557304 -0.570294   \n",
       "8401   0  0.273821  1.022298     0.405698  3.733454 -1.154471 -0.584378   \n",
       "8402   0  0.348503  1.080686     0.478248  3.100938  0.597167  1.154672   \n",
       "8403   0  0.282846  1.051722     0.435547  3.718361 -0.942799  0.292007   \n",
       "8404   0  0.363169  1.057844     0.528093  2.912813  0.941154  0.474336   \n",
       "...   ..       ...       ...          ...       ...       ...       ...   \n",
       "9595  10  0.275401  1.182630     0.414005  4.294205 -1.117401  4.190975   \n",
       "9596  10  0.204631  1.189241     0.291487  5.811628 -2.777285  4.387865   \n",
       "9597  10  0.290996  1.110189     0.398633  3.815133 -0.751634  2.033375   \n",
       "9598  10  0.301910  1.143009     0.420446  3.785924 -0.495647  3.010903   \n",
       "9599  10  0.250010  1.143407     0.439890  4.573453 -1.712957  3.022742   \n",
       "\n",
       "      Circularity_N     MOE_N  \n",
       "8400       0.593287 -0.750118  \n",
       "8401      -1.154553  1.135317  \n",
       "8402       0.561266 -0.385199  \n",
       "8403      -0.448633  1.099036  \n",
       "8404       1.740125 -0.837434  \n",
       "...             ...       ...  \n",
       "9595      -0.958109  2.483317  \n",
       "9596      -3.855693  6.131075  \n",
       "9597      -1.321658  1.331666  \n",
       "9598      -0.805777  1.261450  \n",
       "9599      -0.345922  3.154605  \n",
       "\n",
       "[800 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>EAR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>Circularity</th>\n",
       "      <th>MOE</th>\n",
       "      <th>EAR_N</th>\n",
       "      <th>MAR_N</th>\n",
       "      <th>Circularity_N</th>\n",
       "      <th>MOE_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.986514</td>\n",
       "      <td>0.450053</td>\n",
       "      <td>3.122874</td>\n",
       "      <td>-0.871732</td>\n",
       "      <td>-0.022238</td>\n",
       "      <td>-1.102540</td>\n",
       "      <td>1.043034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.320060</td>\n",
       "      <td>0.967440</td>\n",
       "      <td>0.497489</td>\n",
       "      <td>3.022686</td>\n",
       "      <td>-0.219925</td>\n",
       "      <td>-0.988696</td>\n",
       "      <td>0.254111</td>\n",
       "      <td>-0.950539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.328431</td>\n",
       "      <td>1.006906</td>\n",
       "      <td>0.518270</td>\n",
       "      <td>3.065808</td>\n",
       "      <td>1.091657</td>\n",
       "      <td>1.010933</td>\n",
       "      <td>0.848429</td>\n",
       "      <td>-0.092496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.351223</td>\n",
       "      <td>1.102950</td>\n",
       "      <td>0.536187</td>\n",
       "      <td>3.140313</td>\n",
       "      <td>4.662748</td>\n",
       "      <td>5.877299</td>\n",
       "      <td>1.360857</td>\n",
       "      <td>1.390040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.337345</td>\n",
       "      <td>1.094224</td>\n",
       "      <td>0.504254</td>\n",
       "      <td>3.243631</td>\n",
       "      <td>2.488390</td>\n",
       "      <td>5.435149</td>\n",
       "      <td>0.447582</td>\n",
       "      <td>3.445910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>10</td>\n",
       "      <td>0.174018</td>\n",
       "      <td>1.004202</td>\n",
       "      <td>0.323922</td>\n",
       "      <td>5.770694</td>\n",
       "      <td>-12.219281</td>\n",
       "      <td>7.158256</td>\n",
       "      <td>-3.565366</td>\n",
       "      <td>18.836416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>10</td>\n",
       "      <td>0.208323</td>\n",
       "      <td>1.012277</td>\n",
       "      <td>0.429090</td>\n",
       "      <td>4.859160</td>\n",
       "      <td>-6.492919</td>\n",
       "      <td>7.440192</td>\n",
       "      <td>1.673815</td>\n",
       "      <td>12.068244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>10</td>\n",
       "      <td>0.225565</td>\n",
       "      <td>1.036113</td>\n",
       "      <td>0.425152</td>\n",
       "      <td>4.593413</td>\n",
       "      <td>-3.614978</td>\n",
       "      <td>8.272402</td>\n",
       "      <td>1.477608</td>\n",
       "      <td>10.095060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>10</td>\n",
       "      <td>0.225565</td>\n",
       "      <td>1.017720</td>\n",
       "      <td>0.425152</td>\n",
       "      <td>4.511875</td>\n",
       "      <td>-3.614978</td>\n",
       "      <td>7.630239</td>\n",
       "      <td>1.477608</td>\n",
       "      <td>9.489633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>10</td>\n",
       "      <td>0.192675</td>\n",
       "      <td>1.004988</td>\n",
       "      <td>0.402767</td>\n",
       "      <td>5.215977</td>\n",
       "      <td>-9.105004</td>\n",
       "      <td>7.185674</td>\n",
       "      <td>0.362494</td>\n",
       "      <td>14.717625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5600 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Y       EAR       MAR  Circularity       MOE      EAR_N     MAR_N  \\\n",
       "0      0  0.315900  0.986514     0.450053  3.122874  -0.871732 -0.022238   \n",
       "1      0  0.320060  0.967440     0.497489  3.022686  -0.219925 -0.988696   \n",
       "2      0  0.328431  1.006906     0.518270  3.065808   1.091657  1.010933   \n",
       "3      0  0.351223  1.102950     0.536187  3.140313   4.662748  5.877299   \n",
       "4      0  0.337345  1.094224     0.504254  3.243631   2.488390  5.435149   \n",
       "...   ..       ...       ...          ...       ...        ...       ...   \n",
       "8395  10  0.174018  1.004202     0.323922  5.770694 -12.219281  7.158256   \n",
       "8396  10  0.208323  1.012277     0.429090  4.859160  -6.492919  7.440192   \n",
       "8397  10  0.225565  1.036113     0.425152  4.593413  -3.614978  8.272402   \n",
       "8398  10  0.225565  1.017720     0.425152  4.511875  -3.614978  7.630239   \n",
       "8399  10  0.192675  1.004988     0.402767  5.215977  -9.105004  7.185674   \n",
       "\n",
       "      Circularity_N      MOE_N  \n",
       "0         -1.102540   1.043034  \n",
       "1          0.254111  -0.950539  \n",
       "2          0.848429  -0.092496  \n",
       "3          1.360857   1.390040  \n",
       "4          0.447582   3.445910  \n",
       "...             ...        ...  \n",
       "8395      -3.565366  18.836416  \n",
       "8396       1.673815  12.068244  \n",
       "8397       1.477608  10.095060  \n",
       "8398       1.477608   9.489633  \n",
       "8399       0.362494  14.717625  \n",
       "\n",
       "[5600 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop([\"Y\"],axis=1)\n",
    "y_test = df_test[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('Y',axis=1)\n",
    "y_train = df_train['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        if i % 612 == 0 or (i+1) % 612 == 0:\n",
    "            y_pred[i] = 0\n",
    "            pass\n",
    "        else:\n",
    "            if i+1 == range(len(y_pred)):\n",
    "                average = float(y_pred[i-1] +  y_pred[i])/2\n",
    "                print(\"Fuck\")\n",
    "            else:\n",
    "                average = float(y_pred[i-1] +  y_pred[i] + y_pred[i+1])/3\n",
    "                                \n",
    "            if average >= 0.5:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        if i % 400 == 0 or (i+1) % 400 == 0:\n",
    "            y_pred[i] = 0\n",
    "            pass\n",
    "        else: \n",
    "            average = float(y_pred[i-1] +  y_pred[i] + y_pred[i+1])/3\n",
    "            if average >= 0.5:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81125, 0.810752930744659]\n",
      "[[345  55]\n",
      " [ 96 304]]\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred_1 = clf.predict(X_test)\n",
    "#y_pred_1 = average(y_pred_1)\n",
    "y_score_1 = clf.predict_proba(X_test)[:,1]\n",
    "acc1 = accuracy_score(y_test, y_pred_1)\n",
    "f1_score_1 = metrics.f1_score(y_test, y_pred_1,average='macro')\n",
    "print([acc1,f1_score_1])\n",
    "print(confusion_matrix(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0, 10,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0,\n",
       "        0,  0, 10,  0, 10, 10,  0,  0,  0,  0,  0,  0, 10,  0,  0, 10,  0,\n",
       "        0,  0,  0,  0, 10,  0,  0,  0, 10, 10, 10, 10, 10,  0,  0,  0, 10,\n",
       "       10,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,\n",
       "        0,  0,  0,  0,  0, 10,  0,  0, 10,  0,  0,  0, 10,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10,  0,  0, 10,\n",
       "        0,  0,  0, 10,  0,  0, 10, 10,  0, 10,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10,  0,  0, 10,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0, 10,  0, 10,  0, 10,  0,  0,  0,  0, 10,  0,\n",
       "        0,  0,  0, 10,  0, 10,  0,  0, 10, 10,  0, 10,  0, 10,  0, 10,  0,\n",
       "        0, 10, 10,  0,  0, 10,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0, 10,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0, 10,  0, 10,  0, 10,  0,  0,  0,  0,  0,  0, 10,  0,\n",
       "        0,  0, 10, 10,  0,  0,  0, 10,  0,  0, 10,  0, 10, 10, 10, 10, 10,\n",
       "       10, 10,  0, 10, 10,  0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10,  0, 10,  0,  0,  0,  0,  0,  0, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  0,\n",
       "        0, 10,  0,  0,  0,  0, 10,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,\n",
       "        0, 10, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10, 10,\n",
       "       10,  0,  0,  0, 10,  0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10,  0, 10, 10, 10,  0, 10,  0, 10, 10, 10, 10, 10, 10,\n",
       "        0, 10, 10,  0,  0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10,  0,  0,  0,  0,  0,  0,  0, 10, 10, 10, 10, 10, 10,  0,\n",
       "       10, 10,  0, 10, 10,  0, 10, 10,  0, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        0, 10, 10, 10, 10, 10, 10, 10,  0, 10, 10, 10,  0, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10,  0,  0,  0, 10, 10, 10, 10, 10, 10,  0, 10,  0,\n",
       "        0, 10, 10, 10, 10,  0, 10, 10, 10, 10, 10, 10, 10, 10,  0, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10,  0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10,  0, 10, 10, 10, 10,  0, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3_list = []\n",
    "f1_score3_list = []\n",
    "roc_3_list = []\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for i in range(1,30):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "    neigh.fit(X_train, y_train) \n",
    "    pred_KN = neigh.predict(X_test)\n",
    "    #pred_KN = average(pred_KN)\n",
    "    y_score_3 = neigh.predict_proba(X_test)[:,1]\n",
    "    acc3_list.append(accuracy_score(y_test, pred_KN))\n",
    "    f1_score3_list.append(metrics.f1_score(y_test, pred_KN,average='micro'))\n",
    "    #roc_3_list.append(metrics.roc_auc_score(y_test, y_score_3,multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,\n",
       "        0,  0, 10,  0,  0,  0,  0,  0,  0, 10,  0, 10, 10,  0,  0,  0,  0,\n",
       "        0, 10,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10, 10,  0, 10, 10,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0,\n",
       "        0,  0, 10,  0,  0,  0,  0,  0,  0,  0, 10,  0, 10,  0,  0, 10,  0,\n",
       "        0,  0,  0,  0, 10,  0, 10, 10,  0, 10,  0,  0,  0, 10,  0,  0, 10,\n",
       "        0,  0, 10, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0, 10,  0,  0,  0,  0,  0,\n",
       "        0,  0, 10,  0,  0, 10,  0,  0, 10,  0,  0,  0, 10,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10,  0,  0, 10, 10,\n",
       "        0,  0, 10, 10,  0,  0,  0,  0, 10, 10, 10, 10,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10, 10, 10,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0, 10,  0, 10, 10, 10,  0,  0, 10,  0,  0, 10,  0,\n",
       "        0,  0,  0, 10,  0,  0,  0, 10, 10, 10,  0, 10,  0,  0,  0,  0,  0,\n",
       "        0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0, 10,  0, 10,\n",
       "        0, 10,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "       10,  0,  0, 10,  0, 10, 10, 10, 10, 10, 10,  0,  0, 10, 10,  0, 10,\n",
       "        0,  0, 10, 10, 10,  0, 10,  0,  0,  0, 10,  0,  0,  0, 10, 10, 10,\n",
       "       10,  0,  0,  0, 10, 10,  0, 10,  0, 10, 10,  0,  0, 10,  0, 10,  0,\n",
       "        0,  0, 10,  0, 10,  0,  0,  0,  0, 10,  0, 10, 10, 10, 10, 10, 10,\n",
       "       10,  0, 10, 10, 10, 10,  0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10,  0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10,  0, 10,  0,  0, 10,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  0,\n",
       "        0, 10,  0, 10,  0,  0, 10,  0,  0, 10, 10, 10,  0,  0,  0,  0,  0,\n",
       "        0, 10,  0, 10,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  0, 10, 10,\n",
       "        0, 10,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10, 10, 10,  0, 10, 10,\n",
       "        0,  0,  0, 10,  0,  0,  0,  0, 10,  0,  0,  0,  0, 10, 10, 10, 10,\n",
       "       10,  0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10,  0, 10,  0,  0,  0, 10,  0,  0, 10,  0, 10,  0, 10,\n",
       "        0, 10, 10,  0, 10,  0, 10,  0, 10, 10,  0,  0, 10, 10,  0,  0, 10,\n",
       "        0, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0, 10, 10,  0,\n",
       "        0, 10,  0, 10,  0,  0, 10, 10, 10,  0,  0,  0,  0, 10, 10,  0,  0,\n",
       "       10, 10, 10, 10,  0, 10,  0,  0,  0,  0,  0, 10,  0,  0,  0,  0, 10,\n",
       "        0, 10, 10,  0, 10, 10, 10,  0,  0, 10, 10, 10, 10, 10,  0, 10,  0,\n",
       "        0,  0,  0, 10,  0, 10, 10,  0, 10, 10,  0,  0,  0,  0,  0, 10,  0,\n",
       "        0,  0,  0,  0,  0, 10,  0,  0,  0, 10, 10, 10,  0,  0, 10, 10, 10,\n",
       "       10, 10,  0, 10, 10, 10, 10, 10, 10,  0, 10, 10, 10, 10,  0,  0, 10,\n",
       "       10, 10, 10, 10,  0, 10, 10,  0, 10,  0, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10,  0, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10,  0, 10, 10, 10, 10, 10, 10, 10,  0,  0,\n",
       "       10], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_KN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6725,\n",
       " 0.66875,\n",
       " 0.68,\n",
       " 0.65375,\n",
       " 0.6625,\n",
       " 0.66,\n",
       " 0.6675,\n",
       " 0.6725,\n",
       " 0.68125,\n",
       " 0.6775,\n",
       " 0.67625,\n",
       " 0.675,\n",
       " 0.6725,\n",
       " 0.66875,\n",
       " 0.6675,\n",
       " 0.6675,\n",
       " 0.6675,\n",
       " 0.67,\n",
       " 0.66875,\n",
       " 0.67,\n",
       " 0.66125,\n",
       " 0.66625,\n",
       " 0.66375,\n",
       " 0.6675,\n",
       " 0.66875,\n",
       " 0.67125,\n",
       " 0.6725,\n",
       " 0.67,\n",
       " 0.67125]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc3_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc3_list.index(max(acc3_list))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68125, 0.68125]\n",
      "[[329  71]\n",
      " [184 216]]\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "neigh = KNeighborsClassifier(n_neighbors=acc3_list.index(max(acc3_list))+1)\n",
    "neigh.fit(X_train, y_train) \n",
    "pred_KN = neigh.predict(X_test)\n",
    "#pred_KN = average(pred_KN)\n",
    "y_score_3 = neigh.predict_proba(X_test)[:,1]\n",
    "acc3 = accuracy_score(y_test, pred_KN)\n",
    "f1_score_3 = metrics.f1_score(y_test, pred_KN,average='micro')\n",
    "#roc_3 = metrics.roc_auc_score(y_test, y_score_3)\n",
    "print([acc3,f1_score_3])\n",
    "print(confusion_matrix(y_test, pred_KN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "F1_score_4_list = []\n",
    "acc4_list = []\n",
    "roc_4_list = []\n",
    "mlp = []\n",
    "\n",
    "hidden_units = [10,20,30,40,50,60,70]\n",
    "optimizer = ['sgd','adam','lbfgs']\n",
    "activation = ['logistic','tanh','relu']\n",
    "for j in activation:\n",
    "    for i in optimizer:\n",
    "        for k in hidden_units:\n",
    "            clf_MLP = MLPClassifier(hidden_layer_sizes= k, activation =  j, solver= i)\n",
    "            clf_MLP.fit(X_train, y_train)\n",
    "            pred_MLP = clf_MLP.predict(X_test)\n",
    "            #pred_MLP = average(pred_MLP)\n",
    "            y_score_4 = clf_MLP.predict_proba(X_test)[:,1]\n",
    "            acc4_list.append(accuracy_score(y_test,pred_MLP))\n",
    "            #roc_4_list.append(metrics.roc_auc_score(y_test, y_score_4))\n",
    "            F1_score_4_list.append(metrics.f1_score(y_test, pred_MLP,average='micro'))\n",
    "            mlp.append([j,i,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy:  0.805\n",
      "Best Combination: ['tanh', 'sgd', 70]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Accuracy: \", max(acc4_list))\n",
    "min_index = acc4_list.index(max(acc4_list))\n",
    "print(\"Best Combination:\", mlp[min_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81, 0.81]\n",
      "[[346  54]\n",
      " [ 98 302]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_MLP = MLPClassifier(hidden_layer_sizes= mlp[min_index][2], activation =  mlp[min_index][0], solver= mlp[min_index][1])\n",
    "clf_MLP.fit(X_train, y_train)\n",
    "pred_MLP = clf_MLP.predict(X_test)\n",
    "y_score_4 = clf_MLP.predict_proba(X_test)[:,1]\n",
    "acc4 = accuracy_score(y_test,pred_MLP)\n",
    "f1_score_4 = metrics.f1_score(y_test, pred_MLP,average='micro')\n",
    "print([acc4,f1_score_4])\n",
    "print(confusion_matrix(y_test, pred_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.78      0.86      0.82       400\n",
      "      sleepy       0.85      0.76      0.80       400\n",
      "\n",
      "    accuracy                           0.81       800\n",
      "   macro avg       0.81      0.81      0.81       800\n",
      "weighted avg       0.81      0.81      0.81       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "target_names = ['alert', 'sleepy']\n",
    "\n",
    "print(classification_report(y_test, pred_MLP, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74, 0.74]\n",
      "[[339  61]\n",
      " [147 253]]\n"
     ]
    }
   ],
   "source": [
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, y_train)\n",
    "pred_NB = clf_NB.predict(X_test)\n",
    "#pred_NB = average(pred_NB)\n",
    "y_score_2 = clf_NB.predict_proba(X_test)[:,1]\n",
    "acc2 = accuracy_score(y_test, pred_NB)\n",
    "f1_score_2 = metrics.f1_score(y_test, pred_NB,average='micro')\n",
    "#roc_2 = metrics.roc_auc_score(y_test, y_score_2)\n",
    "print([acc2,f1_score_2])\n",
    "print(confusion_matrix(y_test, pred_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "acc5=[]\n",
    "max_depth = []\n",
    "for i in [2,3,4,5,6,7,8,9,10]:\n",
    "    clf_DT = DecisionTreeClassifier(random_state=0, max_depth = i)\n",
    "    clf_DT.fit(X_train, y_train)\n",
    "    pred_DT = clf_DT.predict(X_test)\n",
    "    #pred_DT = average(pred_DT)\n",
    "    acc5.append(accuracy_score(pred_DT, y_test))\n",
    "    max_depth.append(i)\n",
    "print (max(acc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "parameters = { 'C':np.arange(1,15,0.5)}\n",
    "svc = svm.SVC()\n",
    "SVM=GridSearchCV(svc, parameters)\n",
    "SVM.fit(X_train,y_train)\n",
    "SVM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74875"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nataw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
